# -*- coding: utf-8 -*-
"""GIS_FTL_STREAMLITAPP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eTBl5EMKGm7xUVFf9_pF95wgJnKbmf2X
"""

# from google.colab import drive
# drive.mount('/content/drive')

# !pip install geopandas
# !pip install pandas
# !pip install pandas
# !pip install shapely
# !pip install matplotlib
# !pip install  rasterio
# !pip install streamlit
# !pip install rasterstats

# --- Imports ---
import geopandas as gpd
import pandas as pd
import rasterio
from rasterstats import zonal_stats
from shapely import wkt
import matplotlib.pyplot as plt
import streamlit as st
import gdown
import os

# --- Load Khartoum boundary ---
sudan_gdf = gpd.read_file("Khartoum.shp").to_crs("EPSG:4326")
khartoum_gdf = sudan_gdf[sudan_gdf['id'] == 'SDKH']

# --- Load buildings CSV and convert WKT to GeoDataFrame ---
# buildings_df = pd.read_csv("/content/drive/My Drive/GIS_FTL_LAST/169_buildings.csv")
# buildings_df['geometry'] = buildings_df['geometry'].apply(wkt.loads)
# buildings_gdf = gpd.GeoDataFrame(buildings_df, geometry='geometry', crs='EPSG:4326')
# https://drive.google.com/file/d/1t_wdIU9zDTLeJ0ImEygGARZtqseM0rwa/view?usp=drive_link
# url = "https://drive.google.com/uc?id=1t_wdIU9zDTLeJ0ImEygGARZtqseM0rwa"
# url = "https://drive.google.com/uc?id=1t_wdIU9zDTLeJ0ImEygGARZtqseM0rwa"
# https://drive.google.com/file/d/1lgJB2uDqc8GutFgfO7gxJZm9DptVgphU/view?usp=sharing
# buildings_df = pd.read_csv(url) 
file_id = "1lgJB2uDqc8GutFgfO7gxJZm9DptVgphU"
gdown.download(f"https://drive.google.com/uc?id={file_id}", "169_buildings.csv", quiet=False)
buildings_df = pd.read_csv("169_buildings.csv")
st.subheader("üìç Sample Data")
st.dataframe(buildings_df.head())
# buildings_df['geometry'] = buildings_df['geometry'].apply(wkt.loads)
# buildings_gdf = gpd.GeoDataFrame(buildings_df, geometry='geometry', crs='EPSG:4326')
# # # --- Clip buildings to Khartoum ---
# buildings_in_khartoum = gpd.sjoin(buildings_gdf, khartoum_gdf, how='inner', predicate='intersects')

# # --- Efficient zonal stats function with chunking ---
# def get_flooded_buildings_chunked(flood_path, buildings_gdf, chunk_size=50000):
#     flooded_chunks = []
#     buildings_gdf = buildings_gdf.to_crs("EPSG:4326")
#     for i in range(0, len(buildings_gdf), chunk_size):
#         chunk = buildings_gdf.iloc[i:i+chunk_size]
#         stats = zonal_stats(chunk, flood_path, stats=["max"], nodata=0)
#         flooded_idx = [i for i, s in enumerate(stats) if s and s.get("max") == 1]
#         flooded_chunks.append(chunk.iloc[flooded_idx])
#     return pd.concat(flooded_chunks).to_crs("EPSG:4326")

# # --- Load flood masks and compute affected buildings ---
# flood_files = {
#     2018: "FloodMask_2018.tif",
#     2019: "FloodMask_2019.tif",
#     2020: "FloodMask_2020.tif",
#     # 2021: "/content/drive/My Drive/GIS_FTL_LAST/FloodMask_2021.tif",
#     # 2022: "/content/drive/My Drive/GIS_FTL_LAST/FloodMask_2022.tif"
# }

# flooded_by_year = {}
# for year, path in flood_files.items():
#     if os.path.exists(path):
#         flooded_by_year[year] = get_flooded_buildings_chunked(path, buildings_in_khartoum)

# # --- Streamlit UI ---
# st.title("üåä Flood Impact on Buildings in Khartoum (2017‚Äì2022)")
# year = st.selectbox("Select Year", sorted(flooded_by_year.keys()))
# flooded = flooded_by_year[year]

# st.write(f"üè† Buildings affected in {year}: **{len(flooded)}**")

# fig, ax = plt.subplots(figsize=(10, 8))
# khartoum_gdf.plot(ax=ax, edgecolor='black', facecolor='none')
# buildings_in_khartoum.plot(ax=ax, color='gray', alpha=0.3, label='All Buildings')
# flooded.plot(ax=ax, color='red', label='Flooded Buildings')
# ax.legend()
# st.pyplot(fig)

# # --- Optional download ---
# st.download_button(
#     label=f"Download Flooded Buildings ({year})",
#     data=flooded.to_csv(index=False),
#     file_name=f"flooded_buildings_{year}.csv",
#     mime="text/csv"
# )
